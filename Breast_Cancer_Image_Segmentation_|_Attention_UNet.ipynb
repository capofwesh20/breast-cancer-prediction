{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Breast Cancer Image Segmentation | Attention UNet ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capofwesh20/breast-cancer-prediction/blob/main/Breast_Cancer_Image_Segmentation_%7C_Attention_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "aryashah2k_breast_ultrasound_images_dataset_path = kagglehub.dataset_download('aryashah2k/breast-ultrasound-images-dataset')\n",
        "utkarshsaxenadn_breast_cancer_detection_unet_path = kagglehub.dataset_download('utkarshsaxenadn/breast-cancer-detection-unet')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "L_4C5ln-Et49"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "zv0iArqcEt5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About Dataset**\n",
        "\n",
        "* **Breast cancer** is one of the **most common** causes of death among **women worldwide**. Early detection helps in reducing the **number of early deaths**. The data reviews the **medical images of breast cancer** using ultrasound scan. **Breast Ultrasound Dataset** is categorized into **three classes** $:$ **normal, benign, and malignant images**. **Breast ultrasound images** can produce great results in **classification, detection, and segmentation** of breast cancer when combined with machine learning.\n",
        "\n",
        "* The data collected at baseline include **breast ultrasound images among women** in ages between 25 and 75 years old. This data was collected in **2018**. The number of patients is **600 female patients**. The dataset consists of **780 images** with an **average image size of 500*500 pixels**. The images are in PNG format. The ground truth images are presented with original images. The images are categorized into **three classes, which are normal, benign, and malignant**.\n",
        "\n",
        "**Approach**\n",
        "\n",
        "* **AttentionUNet/UNet** is the best know model for **Multi-Class Segmentation**, thats why we will be creating a **Attention UNet Model**.\n",
        "* As the **image Dataset** is **old**, please **do not use it for any new medical operations**.\n",
        "* All the images are of 500 X 500 pixels, **Kaggle RAM** wil not be enough so we will be resizing the Image to **256 X 256 pixels**.\n",
        "\n",
        "**Model Architecture**\n",
        "\n",
        "* The Model will consist of a **Encoder Block, Decoder Block and a Attention Gate.**"
      ],
      "metadata": {
        "id": "h0od96kQEt5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "g_3rM2Af6CwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install tf_explain\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ni0qxGc3L1bu",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:34.482836Z",
          "iopub.execute_input": "2022-09-05T03:01:34.48354Z",
          "iopub.status.idle": "2022-09-05T03:01:46.062539Z",
          "shell.execute_reply.started": "2022-09-05T03:01:34.483427Z",
          "shell.execute_reply": "2022-09-05T03:01:46.061242Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# common\n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import tensorflow.image as tfi\n",
        "\n",
        "# Data\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Data Viz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Add\n",
        "from keras.layers import Multiply\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# Callbacks\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tf_explain.core.grad_cam import GradCAM\n",
        "\n",
        "# Metrics\n",
        "from keras.metrics import MeanIoU"
      ],
      "metadata": {
        "id": "4zXw8Ycj6D0l",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:46.064835Z",
          "iopub.execute_input": "2022-09-05T03:01:46.065613Z",
          "iopub.status.idle": "2022-09-05T03:01:51.8092Z",
          "shell.execute_reply.started": "2022-09-05T03:01:46.065561Z",
          "shell.execute_reply": "2022-09-05T03:01:51.808145Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "8zckEunbDxLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image, SIZE):\n",
        "    return np.round(tfi.resize(img_to_array(load_img(image))/255.,(SIZE, SIZE)),4)\n",
        "\n",
        "def load_images(image_paths, SIZE, mask=False, trim=None):\n",
        "    if trim is not None:\n",
        "        image_paths = image_paths[:trim]\n",
        "\n",
        "    if mask:\n",
        "        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 1))\n",
        "    else:\n",
        "        images = np.zeros(shape=(len(image_paths), SIZE, SIZE, 3))\n",
        "\n",
        "    for i,image in enumerate(image_paths):\n",
        "        img = load_image(image,SIZE)\n",
        "        if mask:\n",
        "            images[i] = img[:,:,:1]\n",
        "        else:\n",
        "            images[i] = img\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "Sv5MB-unO3tY",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:51.811434Z",
          "iopub.execute_input": "2022-09-05T03:01:51.812416Z",
          "iopub.status.idle": "2022-09-05T03:01:51.820192Z",
          "shell.execute_reply.started": "2022-09-05T03:01:51.812376Z",
          "shell.execute_reply": "2022-09-05T03:01:51.819217Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image, title=None, cmap=None, alpha=1):\n",
        "    plt.imshow(image, cmap=cmap, alpha=alpha)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "def show_mask(image, mask, cmap=None, alpha=0.4):\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(tf.squeeze(mask), cmap=cmap, alpha=alpha)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "PiQzRTMlnNAH",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:51.822457Z",
          "iopub.execute_input": "2022-09-05T03:01:51.823162Z",
          "iopub.status.idle": "2022-09-05T03:01:51.83941Z",
          "shell.execute_reply.started": "2022-09-05T03:01:51.823116Z",
          "shell.execute_reply": "2022-09-05T03:01:51.838506Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 256"
      ],
      "metadata": {
        "id": "1BVzD2xgFkgt",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:51.842062Z",
          "iopub.execute_input": "2022-09-05T03:01:51.843276Z",
          "iopub.status.idle": "2022-09-05T03:01:51.849482Z",
          "shell.execute_reply.started": "2022-09-05T03:01:51.843237Z",
          "shell.execute_reply": "2022-09-05T03:01:51.848375Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'\n",
        "classes = sorted(os.listdir(root_path))\n",
        "classes"
      ],
      "metadata": {
        "id": "wP8jF-PHO9Ch",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:51.850897Z",
          "iopub.execute_input": "2022-09-05T03:01:51.851351Z",
          "iopub.status.idle": "2022-09-05T03:01:51.870184Z",
          "shell.execute_reply.started": "2022-09-05T03:01:51.851316Z",
          "shell.execute_reply": "2022-09-05T03:01:51.869055Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_mask_paths = sorted([sorted(glob(root_path + name + \"/*mask.png\")) for name in classes])\n",
        "double_mask_paths = sorted([sorted(glob(root_path + name + \"/*mask_1.png\")) for name in classes])"
      ],
      "metadata": {
        "id": "gVbNZJujO8_K",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:51.871752Z",
          "iopub.execute_input": "2022-09-05T03:01:51.872095Z",
          "iopub.status.idle": "2022-09-05T03:01:52.237175Z",
          "shell.execute_reply.started": "2022-09-05T03:01:51.872062Z",
          "shell.execute_reply": "2022-09-05T03:01:52.236207Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = []\n",
        "mask_paths = []\n",
        "for class_path in single_mask_paths:\n",
        "    for path in class_path:\n",
        "        img_path = path.replace('_mask','')\n",
        "        image_paths.append(img_path)\n",
        "        mask_paths.append(path)"
      ],
      "metadata": {
        "id": "hizq3EyITaeI",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:52.239503Z",
          "iopub.execute_input": "2022-09-05T03:01:52.240195Z",
          "iopub.status.idle": "2022-09-05T03:01:52.24625Z",
          "shell.execute_reply.started": "2022-09-05T03:01:52.240157Z",
          "shell.execute_reply": "2022-09-05T03:01:52.245286Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image(image_paths[0], SIZE))"
      ],
      "metadata": {
        "id": "RYwn8wnqTpa4",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:52.247792Z",
          "iopub.execute_input": "2022-09-05T03:01:52.248193Z",
          "iopub.status.idle": "2022-09-05T03:01:55.27378Z",
          "shell.execute_reply.started": "2022-09-05T03:01:52.248159Z",
          "shell.execute_reply": "2022-09-05T03:01:55.272487Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_mask(load_image(image_paths[0], SIZE), load_image(mask_paths[0], SIZE)[:,:,0], alpha=0.6)"
      ],
      "metadata": {
        "id": "1G1w3V66UyPC",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:55.280056Z",
          "iopub.execute_input": "2022-09-05T03:01:55.284839Z",
          "iopub.status.idle": "2022-09-05T03:01:55.639848Z",
          "shell.execute_reply.started": "2022-09-05T03:01:55.284784Z",
          "shell.execute_reply": "2022-09-05T03:01:55.638815Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Approach**"
      ],
      "metadata": {
        "id": "pIjk4Ps8RDvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below here I have explained my strategy to tackel the multiple mask Images."
      ],
      "metadata": {
        "id": "6KgLQ53URF5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))"
      ],
      "metadata": {
        "id": "64r6IQglO881",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:55.641121Z",
          "iopub.execute_input": "2022-09-05T03:01:55.64203Z",
          "iopub.status.idle": "2022-09-05T03:01:55.784943Z",
          "shell.execute_reply.started": "2022-09-05T03:01:55.641981Z",
          "shell.execute_reply": "2022-09-05T03:01:55.783613Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE))"
      ],
      "metadata": {
        "id": "RS3v3F9wO86k",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:55.786867Z",
          "iopub.execute_input": "2022-09-05T03:01:55.78724Z",
          "iopub.status.idle": "2022-09-05T03:01:55.911419Z",
          "shell.execute_reply.started": "2022-09-05T03:01:55.787203Z",
          "shell.execute_reply": "2022-09-05T03:01:55.910011Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE))"
      ],
      "metadata": {
        "id": "J7IujS3sPhst",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:55.913537Z",
          "iopub.execute_input": "2022-09-05T03:01:55.913943Z",
          "iopub.status.idle": "2022-09-05T03:01:56.050891Z",
          "shell.execute_reply.started": "2022-09-05T03:01:55.913905Z",
          "shell.execute_reply": "2022-09-05T03:01:56.049403Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't want the data this way, as both the masks belongs to the same class. A better idea can be to merge both these images"
      ],
      "metadata": {
        "id": "68dZSoJ6PkSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.zeros((1,SIZE,SIZE,3))\n",
        "mask1 = load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask_1.png', SIZE)\n",
        "mask2 = load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100)_mask.png', SIZE)\n",
        "\n",
        "img = img + mask1 + mask2\n",
        "img = img[0,:,:,0]\n",
        "show_image(img, cmap='gray')"
      ],
      "metadata": {
        "id": "FhVS-PhZPhqP",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:56.052785Z",
          "iopub.execute_input": "2022-09-05T03:01:56.053129Z",
          "iopub.status.idle": "2022-09-05T03:01:56.185001Z",
          "shell.execute_reply.started": "2022-09-05T03:01:56.053095Z",
          "shell.execute_reply": "2022-09-05T03:01:56.183861Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first merged them and them simple used the 1st channel because that is enough."
      ],
      "metadata": {
        "id": "O942E22FRNP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\n",
        "plt.imshow(img, cmap='binary', alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YHPoLXTFP4C6",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:56.186807Z",
          "iopub.execute_input": "2022-09-05T03:01:56.18767Z",
          "iopub.status.idle": "2022-09-05T03:01:56.360032Z",
          "shell.execute_reply.started": "2022-09-05T03:01:56.187632Z",
          "shell.execute_reply": "2022-09-05T03:01:56.359079Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\n",
        "plt.imshow(img, cmap='gray', alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "On868uBCP5Jj",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:56.361822Z",
          "iopub.execute_input": "2022-09-05T03:01:56.362513Z",
          "iopub.status.idle": "2022-09-05T03:01:56.518954Z",
          "shell.execute_reply.started": "2022-09-05T03:01:56.36246Z",
          "shell.execute_reply": "2022-09-05T03:01:56.51779Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(load_image('../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (100).png', SIZE))\n",
        "plt.imshow(img, alpha=0.4)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gXt6YcqKP5Gu",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:56.523975Z",
          "iopub.execute_input": "2022-09-05T03:01:56.526191Z",
          "iopub.status.idle": "2022-09-05T03:01:56.693508Z",
          "shell.execute_reply.started": "2022-09-05T03:01:56.526153Z",
          "shell.execute_reply": "2022-09-05T03:01:56.692534Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how it looks with different cmaps. But you can drop them as then are very less in number (i.e 16) and this will not affect training much."
      ],
      "metadata": {
        "id": "rGkJpMajRXuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Work**"
      ],
      "metadata": {
        "id": "PR-k_kiIRc5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = load_images(image_paths, SIZE)\n",
        "masks = load_images(mask_paths, SIZE, mask=True)"
      ],
      "metadata": {
        "id": "NuDIR8PFP5EW",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:01:56.69498Z",
          "iopub.execute_input": "2022-09-05T03:01:56.695622Z",
          "iopub.status.idle": "2022-09-05T03:02:21.829549Z",
          "shell.execute_reply.started": "2022-09-05T03:01:56.695572Z",
          "shell.execute_reply": "2022-09-05T03:02:21.828515Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    id = np.random.randint(len(images))\n",
        "    show_mask(images[id], masks[id], cmap='jet')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Labwwn3nZnoy",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:21.83113Z",
          "iopub.execute_input": "2022-09-05T03:02:21.83152Z",
          "iopub.status.idle": "2022-09-05T03:02:22.995772Z",
          "shell.execute_reply.started": "2022-09-05T03:02:21.831463Z",
          "shell.execute_reply": "2022-09-05T03:02:22.994916Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    id = np.random.randint(len(images))\n",
        "    show_mask(images[id], masks[id], cmap='binary')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hZJQ_FW5azlN",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:22.998098Z",
          "iopub.execute_input": "2022-09-05T03:02:22.998923Z",
          "iopub.status.idle": "2022-09-05T03:02:24.463297Z",
          "shell.execute_reply.started": "2022-09-05T03:02:22.998876Z",
          "shell.execute_reply": "2022-09-05T03:02:24.462125Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    id = np.random.randint(len(images))\n",
        "    show_mask(images[id], masks[id], cmap='afmhot')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RCtDRXrmazie",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:24.464957Z",
          "iopub.execute_input": "2022-09-05T03:02:24.465423Z",
          "iopub.status.idle": "2022-09-05T03:02:25.59319Z",
          "shell.execute_reply.started": "2022-09-05T03:02:24.465381Z",
          "shell.execute_reply": "2022-09-05T03:02:25.592124Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "for i in range(15):\n",
        "    plt.subplot(3,5,i+1)\n",
        "    id = np.random.randint(len(images))\n",
        "    show_mask(images[id], masks[id], cmap='copper')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5BIfKdeRazf_",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:25.594906Z",
          "iopub.execute_input": "2022-09-05T03:02:25.595886Z",
          "iopub.status.idle": "2022-09-05T03:02:26.695234Z",
          "shell.execute_reply.started": "2022-09-05T03:02:25.595854Z",
          "shell.execute_reply": "2022-09-05T03:02:26.69414Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoder**"
      ],
      "metadata": {
        "id": "W6XkXzkHHcCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(Layer):\n",
        "\n",
        "    def __init__(self, filters, rate, pooling=True, **kwargs):\n",
        "        super(EncoderBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.c1 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n",
        "        self.drop = Dropout(rate)\n",
        "        self.c2 = Conv2D(filters, kernel_size=3, strides=1, padding='same', activation='relu', kernel_initializer='he_normal')\n",
        "        self.pool = MaxPool2D()\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.c1(X)\n",
        "        x = self.drop(x)\n",
        "        x = self.c2(x)\n",
        "        if self.pooling:\n",
        "            y = self.pool(x)\n",
        "            return y, x\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"filters\":self.filters,\n",
        "            'rate':self.rate,\n",
        "            'pooling':self.pooling\n",
        "        }"
      ],
      "metadata": {
        "id": "GQksNZycb_Xu",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:26.698904Z",
          "iopub.execute_input": "2022-09-05T03:02:26.699313Z",
          "iopub.status.idle": "2022-09-05T03:02:26.710779Z",
          "shell.execute_reply.started": "2022-09-05T03:02:26.699276Z",
          "shell.execute_reply": "2022-09-05T03:02:26.709289Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decoder**"
      ],
      "metadata": {
        "id": "1cQH7w4OEt5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(Layer):\n",
        "\n",
        "    def __init__(self, filters, rate, **kwargs):\n",
        "        super(DecoderBlock, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "\n",
        "        self.up = UpSampling2D()\n",
        "        self.net = EncoderBlock(filters, rate, pooling=False)\n",
        "\n",
        "    def call(self, X):\n",
        "        X, skip_X = X\n",
        "        x = self.up(X)\n",
        "        c_ = concatenate([x, skip_X])\n",
        "        x = self.net(c_)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"filters\":self.filters,\n",
        "            'rate':self.rate,\n",
        "        }"
      ],
      "metadata": {
        "id": "L_9pZ82jHJsG",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:26.712045Z",
          "iopub.execute_input": "2022-09-05T03:02:26.712856Z",
          "iopub.status.idle": "2022-09-05T03:02:26.723339Z",
          "shell.execute_reply.started": "2022-09-05T03:02:26.712825Z",
          "shell.execute_reply": "2022-09-05T03:02:26.722409Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Gate**"
      ],
      "metadata": {
        "id": "_UNg3YO_Et5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionGate(Layer):\n",
        "\n",
        "    def __init__(self, filters, bn, **kwargs):\n",
        "        super(AttentionGate, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.bn = bn\n",
        "\n",
        "        self.normal = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_normal')\n",
        "        self.down = Conv2D(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer='he_normal')\n",
        "        self.learn = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')\n",
        "        self.resample = UpSampling2D()\n",
        "        self.BN = BatchNormalization()\n",
        "\n",
        "    def call(self, X):\n",
        "        X, skip_X = X\n",
        "\n",
        "        x = self.normal(X)\n",
        "        skip = self.down(skip_X)\n",
        "        x = Add()([x, skip])\n",
        "        x = self.learn(x)\n",
        "        x = self.resample(x)\n",
        "        f = Multiply()([x, skip_X])\n",
        "        if self.bn:\n",
        "            return self.BN(f)\n",
        "        else:\n",
        "            return f\n",
        "        # return f\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"filters\":self.filters,\n",
        "            \"bn\":self.bn\n",
        "        }"
      ],
      "metadata": {
        "id": "QG5cCor3JiaS",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:26.724616Z",
          "iopub.execute_input": "2022-09-05T03:02:26.725865Z",
          "iopub.status.idle": "2022-09-05T03:02:26.737361Z",
          "shell.execute_reply.started": "2022-09-05T03:02:26.725828Z",
          "shell.execute_reply": "2022-09-05T03:02:26.736385Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Callback**"
      ],
      "metadata": {
        "id": "8WSTXFy1Et5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShowProgress(Callback):\n",
        "    def on_epoch_end(self, epochs, logs=None):\n",
        "        id = np.random.randint(200)\n",
        "        exp = GradCAM()\n",
        "        image = images[id]\n",
        "        mask = masks[id]\n",
        "        pred_mask = self.model.predict(image[np.newaxis,...])\n",
        "        cam = exp.explain(\n",
        "            validation_data=(image[np.newaxis,...], mask),\n",
        "            class_index=1,\n",
        "            layer_name='Attention4',\n",
        "            model=self.model\n",
        "        )\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title(\"Original Mask\")\n",
        "        show_mask(image, mask, cmap='copper')\n",
        "\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        show_mask(image, pred_mask, cmap='copper')\n",
        "\n",
        "        plt.subplot(1,3,3)\n",
        "        show_image(cam,title=\"GradCAM\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "IsCTVw0tNeZg",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:26.741172Z",
          "iopub.execute_input": "2022-09-05T03:02:26.741458Z",
          "iopub.status.idle": "2022-09-05T03:02:26.750009Z",
          "shell.execute_reply.started": "2022-09-05T03:02:26.741433Z",
          "shell.execute_reply": "2022-09-05T03:02:26.748822Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention UNet**"
      ],
      "metadata": {
        "id": "aLw6UeTJEt5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputs\n",
        "input_layer = Input(shape=images.shape[-3:])\n",
        "\n",
        "# Encoder\n",
        "p1, c1 = EncoderBlock(32,0.1, name=\"Encoder1\")(input_layer)\n",
        "p2, c2 = EncoderBlock(64,0.1, name=\"Encoder2\")(p1)\n",
        "p3, c3 = EncoderBlock(128,0.2, name=\"Encoder3\")(p2)\n",
        "p4, c4 = EncoderBlock(256,0.2, name=\"Encoder4\")(p3)\n",
        "\n",
        "# Encoding\n",
        "encoding = EncoderBlock(512,0.3, pooling=False, name=\"Encoding\")(p4)\n",
        "\n",
        "# Attention + Decoder\n",
        "\n",
        "a1 = AttentionGate(256, bn=True, name=\"Attention1\")([encoding, c4])\n",
        "d1 = DecoderBlock(256,0.2, name=\"Decoder1\")([encoding, a1])\n",
        "\n",
        "a2 = AttentionGate(128, bn=True, name=\"Attention2\")([d1, c3])\n",
        "d2 = DecoderBlock(128,0.2, name=\"Decoder2\")([d1, a2])\n",
        "\n",
        "a3 = AttentionGate(64, bn=True, name=\"Attention3\")([d2, c2])\n",
        "d3 = DecoderBlock(64,0.1, name=\"Decoder3\")([d2, a3])\n",
        "\n",
        "\n",
        "a4 = AttentionGate(32, bn=True, name=\"Attention4\")([d3, c1])\n",
        "d4 = DecoderBlock(32,0.1, name=\"Decoder4\")([d3, a4])\n",
        "\n",
        "# Output\n",
        "output_layer = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(d4)\n",
        "\n",
        "# Model\n",
        "model = Model(\n",
        "    inputs=[input_layer],\n",
        "    outputs=[output_layer]\n",
        ")\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy', MeanIoU(num_classes=2, name='IoU')]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "cb = [\n",
        "    # EarlyStopping(patience=3, restore_best_weight=True), # With Segmentation I trust on eyes rather than on metrics\n",
        "    ModelCheckpoint(\"AttentionCustomUNet.h5\", save_best_only=True),\n",
        "    ShowProgress()\n",
        "]"
      ],
      "metadata": {
        "id": "JUqEssMcQ8me",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:02:26.751775Z",
          "iopub.execute_input": "2022-09-05T03:02:26.752223Z",
          "iopub.status.idle": "2022-09-05T03:02:27.32494Z",
          "shell.execute_reply.started": "2022-09-05T03:02:26.752189Z",
          "shell.execute_reply": "2022-09-05T03:02:27.323986Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "UETR_vkOEt5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config Training\n",
        "BATCH_SIZE = 8\n",
        "SPE = len(images)//BATCH_SIZE\n",
        "\n",
        "# Training\n",
        "results = model.fit(\n",
        "    images, masks,\n",
        "    validation_split=0.2,\n",
        "    epochs=20, # 15 will be enough for a good Model for better model go with 20+\n",
        "    steps_per_epoch=SPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=cb\n",
        ")"
      ],
      "metadata": {
        "id": "MpBP0XH6RJEY",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:13:21.53732Z",
          "iopub.execute_input": "2022-09-05T03:13:21.538381Z",
          "iopub.status.idle": "2022-09-05T03:17:44.983339Z",
          "shell.execute_reply.started": "2022-09-05T03:13:21.538333Z",
          "shell.execute_reply": "2022-09-05T03:17:44.98227Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations :**\n",
        "\n",
        "* After **12 epochs** model started outputting what we needed.\n",
        "* The model was easily able to detect **black round spots but fails when the shape is irregular**(Not the case with current model because it is trained with hight SPE).\n",
        "\n",
        "* It also gets confused between the dark areas, which makes sense.\n",
        "\n",
        "---\n",
        "**Suggestion :**\n",
        "* Do training in chunks of **20 Epochs**, this will give you a good control **over model and the model will also perform well**.\n",
        "\n",
        "* Here the model is trained on 17 + 17 + 17 = 51 Epochs.\n",
        "\n",
        "* If you give the model a closer look n different images you will find that the model fails at some images, but I can garantee that 9/10 such images would be so tough that even a human will not be a able to detect as many parts of the image look the same.\n"
      ],
      "metadata": {
        "id": "3nJgacMfUMro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "R0kr_PZfEt5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, iou, val_loss, val_accuracy, val_iou = results.history.values()"
      ],
      "metadata": {
        "id": "m5uV8wgMWlao",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:17:44.988759Z",
          "iopub.execute_input": "2022-09-05T03:17:44.989069Z",
          "iopub.status.idle": "2022-09-05T03:17:44.994365Z",
          "shell.execute_reply.started": "2022-09-05T03:17:44.989041Z",
          "shell.execute_reply": "2022-09-05T03:17:44.993398Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Model Loss\")\n",
        "plt.plot(loss, label=\"Training\")\n",
        "plt.plot(val_loss, label=\"Validtion\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.plot(accuracy, label=\"Training\")\n",
        "plt.plot(val_accuracy, label=\"Validtion\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Model IoU\")\n",
        "plt.plot(iou, label=\"Training\")\n",
        "plt.plot(val_iou, label=\"Validtion\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KUgo9t-bW2aH",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:17:44.99582Z",
          "iopub.execute_input": "2022-09-05T03:17:44.996888Z",
          "iopub.status.idle": "2022-09-05T03:17:45.494628Z",
          "shell.execute_reply.started": "2022-09-05T03:17:44.99685Z",
          "shell.execute_reply": "2022-09-05T03:17:45.49377Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suprisingly the results on **Validation Data** are **way better** than the results on **Trainind Data** on **IoU**, this may indicate that the **model can perform way better** than what it can do at the current point. The **Loss is not Perfect** it increases in the last but the model constructions are loooking perfect as this point, that's why **I believe in what I see**. This model seems promising, let's try it on some Images."
      ],
      "metadata": {
        "id": "zfhLm2LOXvOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,25))\n",
        "n=0\n",
        "for i in range(1,(5*3)+1):\n",
        "    plt.subplot(5,3,i)\n",
        "    if n==0:\n",
        "        id = np.random.randint(len(images))\n",
        "        image = images[id]\n",
        "        mask = masks[id]\n",
        "        pred_mask = model.predict(image[np.newaxis,...])\n",
        "\n",
        "        plt.title(\"Original Mask\")\n",
        "        show_mask(image, mask)\n",
        "        n+=1\n",
        "    elif n==1:\n",
        "        plt.title(\"Predicted Mask\")\n",
        "        show_mask(image, pred_mask)\n",
        "        n+=1\n",
        "    elif n==2:\n",
        "        pred_mask = (pred_mask>0.5).astype('float')\n",
        "        plt.title(\"Processed Mask\")\n",
        "        show_mask(image, pred_mask)\n",
        "        n=0\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fvjqCPIMW2XG",
        "execution": {
          "iopub.status.busy": "2022-09-05T03:19:30.271081Z",
          "iopub.execute_input": "2022-09-05T03:19:30.272136Z",
          "iopub.status.idle": "2022-09-05T03:19:32.385401Z",
          "shell.execute_reply.started": "2022-09-05T03:19:30.272095Z",
          "shell.execute_reply": "2022-09-05T03:19:32.384429Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results totally convincing. If you have any suggestions please let me know 👍. **Thanks !!**"
      ],
      "metadata": {
        "id": "PZRL8u8XEt5o"
      }
    }
  ]
}